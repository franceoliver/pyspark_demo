{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb5358f",
   "metadata": {},
   "source": [
    "### Pyspark Handling Missing Values\n",
    "- Dropping Columns\n",
    "- Dropping Rows\n",
    "- Various Parameter In Dropping Functionalitites\n",
    "- Handling Missing Values by Mean, Median and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03995ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484f1443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('DATA/test3.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec50f6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|expereince|salary|\n",
      "+-------+----+----------+------+\n",
      "| Ashley|  49|        12|167579|\n",
      "|Jessica|null|      null|286375|\n",
      "|Michael|  70|         6|294100|\n",
      "| Ashley|  18|        13|155420|\n",
      "|   null|  58|         1|228810|\n",
      "|  Jacob|  24|        10|  null|\n",
      "|  Emily|  49|         5|272015|\n",
      "|  David|  63|         4|178549|\n",
      "|Jessica|  41|        12|162692|\n",
      "|   null|  58|      null|  null|\n",
      "|   John|  31|        22|166813|\n",
      "|  David|  77|        19|203596|\n",
      "|Jessica|  73|         3|176848|\n",
      "|  David|  53|        15|283763|\n",
      "|  Emily|  64|        23|106789|\n",
      "|   John|  70|        18|150195|\n",
      "|Michael|  64|        21|185957|\n",
      "|Matthew|  24|         8|168989|\n",
      "| Ashley|  19|         8|272867|\n",
      "|  Emily|  27|        17|249753|\n",
      "+-------+----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c3cecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|expereince|salary|\n",
      "+----+----------+------+\n",
      "|  49|        12|167579|\n",
      "|null|      null|286375|\n",
      "|  70|         6|294100|\n",
      "|  18|        13|155420|\n",
      "|  58|         1|228810|\n",
      "|  24|        10|  null|\n",
      "|  49|         5|272015|\n",
      "|  63|         4|178549|\n",
      "|  41|        12|162692|\n",
      "|  58|      null|  null|\n",
      "|  31|        22|166813|\n",
      "|  77|        19|203596|\n",
      "|  73|         3|176848|\n",
      "|  53|        15|283763|\n",
      "|  64|        23|106789|\n",
      "|  70|        18|150195|\n",
      "|  64|        21|185957|\n",
      "|  24|         8|168989|\n",
      "|  19|         8|272867|\n",
      "|  27|        17|249753|\n",
      "+----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Drop Columns\n",
    "df_pyspark.drop('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ac258d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|expereince|salary|\n",
      "+-------+---+----------+------+\n",
      "| Ashley| 49|        12|167579|\n",
      "|Michael| 70|         6|294100|\n",
      "| Ashley| 18|        13|155420|\n",
      "|  Emily| 49|         5|272015|\n",
      "|  David| 63|         4|178549|\n",
      "|Jessica| 41|        12|162692|\n",
      "|   John| 31|        22|166813|\n",
      "|  David| 77|        19|203596|\n",
      "|Jessica| 73|         3|176848|\n",
      "|  David| 53|        15|283763|\n",
      "|  Emily| 64|        23|106789|\n",
      "|   John| 70|        18|150195|\n",
      "|Michael| 64|        21|185957|\n",
      "|Matthew| 24|         8|168989|\n",
      "| Ashley| 19|         8|272867|\n",
      "|  Emily| 27|        17|249753|\n",
      "|   John| 35|        19|108132|\n",
      "|  Sarah| 34|        18|276988|\n",
      "|Michael| 72|        14|100630|\n",
      "|  David| 37|        19|138654|\n",
      "+-------+---+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Drop Null Values\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a306811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|expereince|salary|\n",
      "+-------+---+----------+------+\n",
      "| Ashley| 49|        12|167579|\n",
      "|Michael| 70|         6|294100|\n",
      "| Ashley| 18|        13|155420|\n",
      "|  Emily| 49|         5|272015|\n",
      "|  David| 63|         4|178549|\n",
      "|Jessica| 41|        12|162692|\n",
      "|   John| 31|        22|166813|\n",
      "|  David| 77|        19|203596|\n",
      "|Jessica| 73|         3|176848|\n",
      "|  David| 53|        15|283763|\n",
      "|  Emily| 64|        23|106789|\n",
      "|   John| 70|        18|150195|\n",
      "|Michael| 64|        21|185957|\n",
      "|Matthew| 24|         8|168989|\n",
      "| Ashley| 19|         8|272867|\n",
      "|  Emily| 27|        17|249753|\n",
      "|   John| 35|        19|108132|\n",
      "|  Sarah| 34|        18|276988|\n",
      "|Michael| 72|        14|100630|\n",
      "|  David| 37|        19|138654|\n",
      "+-------+---+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any==how\n",
    "# by default it is any\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a24057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|expereince|salary|\n",
      "+-------+----+----------+------+\n",
      "| Ashley|  49|        12|167579|\n",
      "|Jessica|null|      null|286375|\n",
      "|Michael|  70|         6|294100|\n",
      "| Ashley|  18|        13|155420|\n",
      "|   null|  58|         1|228810|\n",
      "|  Jacob|  24|        10|  null|\n",
      "|  Emily|  49|         5|272015|\n",
      "|  David|  63|         4|178549|\n",
      "|Jessica|  41|        12|162692|\n",
      "|   John|  31|        22|166813|\n",
      "|  David|  77|        19|203596|\n",
      "|Jessica|  73|         3|176848|\n",
      "|  David|  53|        15|283763|\n",
      "|  Emily|  64|        23|106789|\n",
      "|   John|  70|        18|150195|\n",
      "|Michael|  64|        21|185957|\n",
      "|Matthew|  24|         8|168989|\n",
      "| Ashley|  19|         8|272867|\n",
      "|  Emily|  27|        17|249753|\n",
      "|   John|  35|        19|108132|\n",
      "+-------+----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## threshold\n",
    "# at least 2 non null values should be present.\n",
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28376096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|expereince|salary|\n",
      "+-------+---+----------+------+\n",
      "| Ashley| 49|        12|167579|\n",
      "|Michael| 70|         6|294100|\n",
      "| Ashley| 18|        13|155420|\n",
      "|   null| 58|         1|228810|\n",
      "|  Jacob| 24|        10|  null|\n",
      "|  Emily| 49|         5|272015|\n",
      "|  David| 63|         4|178549|\n",
      "|Jessica| 41|        12|162692|\n",
      "|   null| 58|      null|  null|\n",
      "|   John| 31|        22|166813|\n",
      "|  David| 77|        19|203596|\n",
      "|Jessica| 73|         3|176848|\n",
      "|  David| 53|        15|283763|\n",
      "|  Emily| 64|        23|106789|\n",
      "|   John| 70|        18|150195|\n",
      "|Michael| 64|        21|185957|\n",
      "|Matthew| 24|         8|168989|\n",
      "| Ashley| 19|         8|272867|\n",
      "|  Emily| 27|        17|249753|\n",
      "|   John| 35|        19|108132|\n",
      "+-------+---+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## subset\n",
    "# only focusing on a specific column\n",
    "df_pyspark.na.drop(how='any', subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c46159f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|expereince|salary|\n",
      "+-------+---+----------+------+\n",
      "| Ashley| 49|        12|167579|\n",
      "|Jessica|  0|         0|286375|\n",
      "|Michael| 70|         6|294100|\n",
      "| Ashley| 18|        13|155420|\n",
      "|   null| 58|         1|228810|\n",
      "|  Jacob| 24|        10|     0|\n",
      "|  Emily| 49|         5|272015|\n",
      "|  David| 63|         4|178549|\n",
      "|Jessica| 41|        12|162692|\n",
      "|   null| 58|         0|     0|\n",
      "|   John| 31|        22|166813|\n",
      "|  David| 77|        19|203596|\n",
      "|Jessica| 73|         3|176848|\n",
      "|  David| 53|        15|283763|\n",
      "|  Emily| 64|        23|106789|\n",
      "|   John| 70|        18|150195|\n",
      "|Michael| 64|        21|185957|\n",
      "|Matthew| 24|         8|168989|\n",
      "| Ashley| 19|         8|272867|\n",
      "|  Emily| 27|        17|249753|\n",
      "+-------+---+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Fill the missing values\n",
    "## Since a recent update you cannot replace all type columns with a single value so you will have to split e.g\n",
    "# https://sparkbyexamples.com/pyspark/pyspark-fillna-fill-replace-null-values/\n",
    "# Int values only (becuase i'm replace with a int value so all int values will be changed)\n",
    "df_pyspark.na.fill(value=0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82a0253c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        name| age|expereince|salary|\n",
      "+------------+----+----------+------+\n",
      "|      Ashley|  49|        12|167579|\n",
      "|     Jessica|null|      null|286375|\n",
      "|     Michael|  70|         6|294100|\n",
      "|      Ashley|  18|        13|155420|\n",
      "|Missing Data|  58|         1|228810|\n",
      "|       Jacob|  24|        10|  null|\n",
      "|       Emily|  49|         5|272015|\n",
      "|       David|  63|         4|178549|\n",
      "|     Jessica|  41|        12|162692|\n",
      "|Missing Data|  58|      null|  null|\n",
      "|        John|  31|        22|166813|\n",
      "|       David|  77|        19|203596|\n",
      "|     Jessica|  73|         3|176848|\n",
      "|       David|  53|        15|283763|\n",
      "|       Emily|  64|        23|106789|\n",
      "|        John|  70|        18|150195|\n",
      "|     Michael|  64|        21|185957|\n",
      "|     Matthew|  24|         8|168989|\n",
      "|      Ashley|  19|         8|272867|\n",
      "|       Emily|  27|        17|249753|\n",
      "+------------+----+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Str values only (becuase i'm replace with a str value so all int values will be changed)\n",
    "df_pyspark.na.fill(value='Missing Data').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "754eebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filling missing data with aggregates of columns \n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['age', 'expereince', 'salary'],\n",
    "                 outputCols=[\"{}_imputed\".format(c) for c in ['age', 'expereince', 'salary']]).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c003b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   name| age|expereince|salary|age_imputed|expereince_imputed|salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "| Ashley|  49|        12|167579|         49|                12|        167579|\n",
      "|Jessica|null|      null|286375|         49|                13|        286375|\n",
      "|Michael|  70|         6|294100|         70|                 6|        294100|\n",
      "| Ashley|  18|        13|155420|         18|                13|        155420|\n",
      "|   null|  58|         1|228810|         58|                 1|        228810|\n",
      "|  Jacob|  24|        10|  null|         24|                10|        187627|\n",
      "|  Emily|  49|         5|272015|         49|                 5|        272015|\n",
      "|  David|  63|         4|178549|         63|                 4|        178549|\n",
      "|Jessica|  41|        12|162692|         41|                12|        162692|\n",
      "|   null|  58|      null|  null|         58|                13|        187627|\n",
      "|   John|  31|        22|166813|         31|                22|        166813|\n",
      "|  David|  77|        19|203596|         77|                19|        203596|\n",
      "|Jessica|  73|         3|176848|         73|                 3|        176848|\n",
      "|  David|  53|        15|283763|         53|                15|        283763|\n",
      "|  Emily|  64|        23|106789|         64|                23|        106789|\n",
      "|   John|  70|        18|150195|         70|                18|        150195|\n",
      "|Michael|  64|        21|185957|         64|                21|        185957|\n",
      "|Matthew|  24|         8|168989|         24|                 8|        168989|\n",
      "| Ashley|  19|         8|272867|         19|                 8|        272867|\n",
      "|  Emily|  27|        17|249753|         27|                17|        249753|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df \n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc499a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
