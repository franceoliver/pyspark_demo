{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9dff886",
   "metadata": {},
   "source": [
    " ### In this document I will cover:\n",
    " - PySpark DataFrame\n",
    " - Reading the Dataset\n",
    " - Checking the Datatypes of the column (Schema)\n",
    " - Selecting Columns and Indexing\n",
    " - Check Describe option similar to Pandas\n",
    " - Adding Columns\n",
    " - Dropping Columns\n",
    " - Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b643b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e59987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('DataFrane').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb7ee945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://nicks-air-2:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrane</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10786e950>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59a23f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the dataset\n",
    "## Option 1\n",
    "# Using inferSchema=True under the csv() will attempt to interpret the column value\n",
    "df_pyspark=spark.read.option('header','True').csv('DATA/test1.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48016a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|experience|\n",
      "+-------+---+----------+\n",
      "| Amanda| 70|        20|\n",
      "|Matthew| 28|         5|\n",
      "|   John| 40|        21|\n",
      "|  David| 18|        16|\n",
      "| Ashley| 36|        13|\n",
      "|Matthew| 35|         5|\n",
      "|Jessica| 70|         9|\n",
      "|Jessica| 49|         6|\n",
      "|  Jacob| 71|        24|\n",
      "| Ashley| 66|         6|\n",
      "| Amanda| 72|         2|\n",
      "|Matthew| 78|        13|\n",
      "| Ashley| 75|        15|\n",
      "|Michael| 59|         4|\n",
      "|  Sarah| 56|        11|\n",
      "|Michael| 71|        17|\n",
      "|Matthew| 50|         6|\n",
      "|  Emily| 61|        13|\n",
      "| Ashley| 33|        25|\n",
      "| Ashley| 25|         8|\n",
      "+-------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Option 2\n",
    "df_pyspark=spark.read.csv('DATA/test1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22201002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Checking the data types of the column\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "784dbe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'experience']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f1cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Amanda', age=70, experience=20),\n",
       " Row(name='Matthew', age=28, experience=5),\n",
       " Row(name='John', age=40, experience=21)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10518aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|experience|\n",
      "+-------+---+----------+\n",
      "| Amanda| 70|        20|\n",
      "|Matthew| 28|         5|\n",
      "|   John| 40|        21|\n",
      "+-------+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb234827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Selecting Columns and Indexing\n",
    "type(df_pyspark.select('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "112e2c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|   name|experience|\n",
      "+-------+----------+\n",
      "| Amanda|        20|\n",
      "|Matthew|         5|\n",
      "|   John|        21|\n",
      "+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['name','experience']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea689bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'name'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dc2b5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('experience', 'int')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check Describe option similar to Pandas\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab7c7d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------------+\n",
      "|summary|   name|               age|       experience|\n",
      "+-------+-------+------------------+-----------------+\n",
      "|  count|1000000|           1000000|          1000000|\n",
      "|   mean|   null|         49.004238|        13.506422|\n",
      "| stddev|   null|18.193161985496097|6.922562147050963|\n",
      "|    min| Amanda|                18|                2|\n",
      "|    max|  Sarah|                80|               25|\n",
      "+-------+-------+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b33fb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Cols in DataFrame\n",
    "df_pyspark=df_pyspark.withColumn('expereince After 2 year', df_pyspark['experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5158915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+-----------------------+\n",
      "|   name|age|experience|expereince After 2 year|\n",
      "+-------+---+----------+-----------------------+\n",
      "| Amanda| 70|        20|                     22|\n",
      "|Matthew| 28|         5|                      7|\n",
      "|   John| 40|        21|                     23|\n",
      "+-------+---+----------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb6b4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping the columns\n",
    "df_pyspark=df_pyspark.drop('expereince After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b6f6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   name|age|experience|\n",
      "+-------+---+----------+\n",
      "| Amanda| 70|        20|\n",
      "|Matthew| 28|         5|\n",
      "|   John| 40|        21|\n",
      "+-------+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83552bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|new name|age|experience|\n",
      "+--------+---+----------+\n",
      "|  Amanda| 70|        20|\n",
      "| Matthew| 28|         5|\n",
      "|    John| 40|        21|\n",
      "+--------+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Rename the columns\n",
    "df_pyspark.withColumnRenamed('name', 'new name').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d8b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
